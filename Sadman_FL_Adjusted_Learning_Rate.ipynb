{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e4b849",
   "metadata": {},
   "source": [
    "source: https://github.com/SadmanSakib93/Federated-Learning-Keras/blob/main/Fed%20Learning%20-%20FL.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24378d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # setting ignore as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41766872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Convolution2D, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling2D, MaxPooling1D\n",
    "from keras import backend as K\n",
    "from keras import backend\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import csv\n",
    "from itertools import repeat\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dab0150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mod_combined_processed.csv')\n",
    "dataset_type = \"large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d47f84e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputx = ['frame_len', 'ip_len', 'ip_ttl', 'ip_proto', 'tcp_srcport', 'tcp_dstport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "947ebdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = data.loc[:, inputx].values\n",
    "Y_full = data['is_malware'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5e4854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_full = scaler.fit_transform(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2919d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(X_full, Y_full, test_size=0.10, random_state=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f1325fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain (802363, 6) yTrain (802363, 2)\n",
      "xTest (89152, 6) yTest (89152, 2)\n"
     ]
    }
   ],
   "source": [
    "outputClasses=len(set(Y_full))\n",
    "# One hot encoding\n",
    "# # to_categorical converts a class vector (integers) to binary class matrix.\n",
    "yTrain = np.array(to_categorical(yTrain))\n",
    "yTest = np.array(to_categorical(yTest))\n",
    "print(\"xTrain\", xTrain.shape, \"yTrain\", yTrain.shape)\n",
    "print(\"xTest\", xTest.shape, \"yTest\", yTest.shape)\n",
    "\n",
    "# FOR TEST SPLIT\n",
    "xServer, xClients, yServer, yClients = train_test_split(xTrain, yTrain, test_size=0.80,random_state=523) \n",
    "\n",
    "def my_metrics(y_true, y_pred):\n",
    "    accuracy=accuracy_score(y_true, y_pred)\n",
    "    precision=precision_score(y_true, y_pred,average='weighted')\n",
    "    recall=recall_score(y_true, y_pred,average='weighted')\n",
    "    f1Score=f1_score(y_true, y_pred, average='weighted') \n",
    "    print(\"Accuracy  : {}\".format(accuracy))\n",
    "    print(\"Precision : {}\".format(precision))\n",
    "    print(\"Recall : {}\".format(recall))\n",
    "    print(\"f1Score : {}\".format(f1Score))\n",
    "    cm=confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    return accuracy, precision, recall, f1Score\n",
    "\n",
    "# verbose of 0 will show you nothing while the model trains\n",
    "# The batch size is a number of samples processed before the model is updated\n",
    "# The number of epochs is the number of complete passes through the training dataset.\n",
    "verbose, epochs, batch_size = 0, 200, 64\n",
    "activationFun='relu'\n",
    "optimizerName='Adam'\n",
    "rate = 0.01\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=rate)\n",
    "\n",
    "def createDeepModel():\n",
    "    model = Sequential()   \n",
    "    model.add(Dense(6, input_dim=X_full.shape[1], activation=activationFun))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(4, activation=activationFun))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(outputClasses, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=adam, \n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "def predictTestData(yPredict, yTest):\n",
    "    #Converting predictions to label\n",
    "    print(\"yPredict\",len(yPredict))\n",
    "    pred = list()\n",
    "    for i in range(len(yPredict)):\n",
    "        # argmax returns the indices of the maximum values along an axis.\n",
    "        pred.append(np.argmax(yPredict[i]))\n",
    "    #Converting one hot encoded test label to label\n",
    "    test = list()\n",
    "    for i in range(len(yTest)):\n",
    "        test.append(np.argmax(yTest[i]))\n",
    "    return my_metrics(test, pred)\n",
    "\n",
    "def sumOfWeights(weights):\n",
    "    return sum(map(sum, weights))\n",
    "\n",
    "def getWeights(model):\n",
    "    allLayersWeights=deepModel.get_weights()\n",
    "    return allLayersWeights\n",
    "    \n",
    "# Initially train central deep model\n",
    "deepModel=createDeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0200c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfIterations=30\n",
    "numOfClients=4 \n",
    "\n",
    "desc = f'batch_{batch_size}_epochs_{epochs}_iterations_{numOfIterations}_dataset_{dataset_type}_lr_{rate}'\n",
    "\n",
    "modelLocation=\"Models/FL_Model_\"+desc+\".h5\"\n",
    "\n",
    "accList, precList, recallList, f1List = [], [], [], []\n",
    "\n",
    "deepModelAggWeights=[]\n",
    "firstClientFlag=True\n",
    "\n",
    "def updateServerModel(clientModel, clientModelWeight):\n",
    "    global firstClientFlag\n",
    "    for ind in range(len(clientModelWeight)):\n",
    "        if(firstClientFlag==True):\n",
    "            deepModelAggWeights.append(clientModelWeight[ind])            \n",
    "        else:\n",
    "            deepModelAggWeights[ind]=(deepModelAggWeights[ind]+clientModelWeight[ind])\n",
    "\n",
    "def updateClientsModels():\n",
    "    global clientsModelList\n",
    "    global deepModel\n",
    "    clientsModelList.clear()\n",
    "    for clientID in range(numOfClients):\n",
    "        m = keras.models.clone_model(deepModel)\n",
    "        m.set_weights(deepModel.get_weights())\n",
    "        clientsModelList.append(m)\n",
    "    \n",
    "# ----- 1. Train central model initially -----\n",
    "def trainInServer():\n",
    "    deepModel.fit(xServer, yServer, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    deepModel.save(modelLocation)\n",
    "trainInServer()\n",
    "\n",
    "# ------- 2. Separate clients data into lists ----------\n",
    "xClientsList=[]\n",
    "yClientsList=[]\n",
    "clientsModelList=[]\n",
    "clientDataInterval=len(xClients)//numOfClients\n",
    "lastLowerBound=0\n",
    "\n",
    "for clientID in range(numOfClients):\n",
    "    xClientsList.append(xClients[lastLowerBound : lastLowerBound+clientDataInterval])\n",
    "    yClientsList.append(yClients[lastLowerBound : lastLowerBound+clientDataInterval])\n",
    "    model=load_model(modelLocation)\n",
    "    clientsModelList.append(model)\n",
    "    lastLowerBound+=clientDataInterval\n",
    "    \n",
    "# ------- 3. Update clients' model with intial server's deep-model ----------\n",
    "for clientID in range(numOfClients):\n",
    "    clientsModelList[clientID].fit(xClientsList[clientID], yClientsList[clientID], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "        \n",
    "start_time = time.time()\n",
    "process = psutil.Process(os.getpid())\n",
    "for iterationNo in range(1,numOfIterations+1):\n",
    "    print(\"Iteration\",iterationNo)\n",
    "    for clientID in range(numOfClients):\n",
    "        print(\"clientID\",clientID)\n",
    "        clientsModelList[clientID].compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        clientsModelList[clientID].fit(xClientsList[clientID], yClientsList[clientID], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "        clientWeight=clientsModelList[clientID].get_weights()\n",
    "        # Find sum of all client's model\n",
    "        updateServerModel(clientsModelList[clientID], clientWeight)\n",
    "        firstClientFlag=False\n",
    "    #Avarage all clients model\n",
    "    for ind in range(len(deepModelAggWeights)):\n",
    "        deepModelAggWeights[ind]/=numOfClients\n",
    "\n",
    "    dw_last=deepModel.get_weights()\n",
    "\n",
    "    for ind in range(len(deepModelAggWeights)): \n",
    "        dw_last[ind]=deepModelAggWeights[ind]\n",
    "     \n",
    "    #Update server's model\n",
    "    deepModel.set_weights(dw_last) \n",
    "    print(\"Server's model updated\")\n",
    "    print(\"Saving model . . .\")\n",
    "    deepModel.save(modelLocation)\n",
    "    # Servers model is updated, now it can be used again by the clients\n",
    "    updateClientsModels()\n",
    "    firstClientFlag=True\n",
    "    deepModelAggWeights.clear()\n",
    "\n",
    "    yPredict = deepModel.predict(xTest)\n",
    "    acc, prec, recall, f1Score= predictTestData(yPredict, yTest)\n",
    "    accList.append(acc)\n",
    "    precList.append(prec)\n",
    "    recallList.append(recall)\n",
    "    f1List.append(f1Score)\n",
    "    print(\"Acc:\\n\", acc)\n",
    "    print(\"Prec:\\n\", prec)\n",
    "    print(\"Recall:\\n\", recall)\n",
    "    print(\"F1-Score:\\n\", f1Score)\n",
    "\n",
    "memoryTraining=process.memory_percent()\n",
    "timeTraining=time.time() - start_time\n",
    "print(\"---Memory---\",memoryTraining)\n",
    "print(\"--- %s seconds (TRAINING)---\" % (timeTraining))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "history = deepModel.fit(xServer, yServer, epochs=epochs, \n",
    "                        validation_data = (xTest,yTest))\n",
    "                        # callbacks=[early_stopping])\n",
    "\n",
    "learningAccs=history.history['val_accuracy']\n",
    "learningLoss=history.history['val_loss']\n",
    "\n",
    "# resultSaveLocation=root_path+'Results/'+algoName+'_Users_vs_TR_vs_Iterations_vs_AccLossMemTime'+'.csv'\n",
    "dfSave=pd.DataFrame(columns=['Clients', 'Iterations to converge', 'Accuracy', 'Loss', 'Memory', 'Time'])\n",
    "dfSaveIndex=0\n",
    "saveList = [numOfClients, len(learningLoss), learningAccs[len(learningAccs)-1], learningLoss[len(learningLoss)-1], memoryTraining, timeTraining]\n",
    "dfSave.loc[dfSaveIndex] = saveList\n",
    "\n",
    "yPredict = deepModel.predict(xTest)\n",
    "acc, prec, recall, f1Score= predictTestData(yPredict, yTest)\n",
    "\n",
    "print(\"Number of users:\", numOfClients)\n",
    "deepModel.save(modelLocation)\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"BatchSize:\", batch_size)\n",
    "print(\"Activation:\", activationFun, \"Optimizer:\", optimizerName)\n",
    "\n",
    "print(\"Iterations:\", numOfIterations)\n",
    "print(\"Memory:\", memoryTraining)\n",
    "print(\"Time:\", timeTraining)\n",
    "print(dfSave)\n",
    "\n",
    "df_performance_timeRounds = pd.DataFrame(\n",
    "    {'Accuracy': accList,\n",
    "     'Precision': precList,\n",
    "     'Recall': recallList,\n",
    "     'F1-Score': f1List \n",
    "    })\n",
    "\n",
    "plt.plot(accList, label=\"Accuracy\", linestyle='dotted', linewidth=4, color='red')\n",
    "plt.plot(precList, label=\"Precision\", color='blue')\n",
    "plt.plot(recallList, label=\"Recall\", color='yellow')\n",
    "plt.plot(f1List, label=\"F1 Score\", color='green')\n",
    "plt.ylabel(\"Value\")\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.title('Scores')\n",
    "plt.legend()\n",
    "plt.annotate(f'Number of Clients: {numOfClients}, Batch Size: {batch_size}, Epochs: {epochs}, \\nIterations: {numOfIterations}, Dataset: {dataset_type}, Learning Rate: {rate}', \n",
    "             (0,0), (0, -40), xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "plt.savefig('Performance/Scores_'+desc+'.png')\n",
    "plt.show()\n",
    "\n",
    "df_performance_timeRounds.to_csv('Performance/Scores_'+desc+'.csv', index=False, encoding='utf8')\n",
    "\n",
    "dfSave.to_csv('Performance/Result_'+desc+'.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0da372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
